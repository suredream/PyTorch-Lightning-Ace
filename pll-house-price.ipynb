{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1AtA7e_OVIplpSEq22IRG6kbnzxNMOoDS",
      "authorship_tag": "ABX9TyPjJc10KRX8tURiKenrO2MX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suredream/PyTorch-Lightning-Ace/blob/main/pll-house-price.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmBRZugdDT4Z",
        "outputId": "b0266ba6-7668-4ad3-ec27-c031df725667"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "Downloading house-prices-advanced-regression-techniques.zip to /content\n",
            "  0% 0.00/199k [00:00<?, ?B/s]\n",
            "100% 199k/199k [00:00<00:00, 84.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# install dependency & watermask\n",
        "# !pip install -q pytorch-lightning\n",
        "# !pip list | grep \"pytorch-lightning\\|torch\"\n",
        "\n",
        "# mount drive\n",
        "# root_dir = '/content/drive/MyDrive/lab/'\n",
        "# import sys; sys.path.append(root_dir+'scripts')\n",
        "# %load_ext lab\n",
        "\n",
        "\n",
        "\n",
        "# install kaggle if needed\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/lab/scripts/kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!pip install -q kaggle \n",
        "\n",
        "# !kaggle datasets download ardamavi/sign-language-digits-dataset\n",
        "!kaggle competitions download -c house-prices-advanced-regression-techniques\n",
        "!unzip house-prices-advanced-regression-techniques.zip > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "lq8zEeeTDvSV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "MCYLPDccEUa4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape)\n",
        "print(test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGVhxNjZEfSj",
        "outputId": "3fadbc46-aeff-4118-dd8e-9834ab02cc84"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1460, 81)\n",
            "(1459, 80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))"
      ],
      "metadata": {
        "id": "NVFxxdJiElvj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 若无法获得测试数据，则可根据训练数据计算均值和标准差\n",
        "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
        "all_features[numeric_features] = all_features[numeric_features].apply(\n",
        "    lambda x: (x - x.mean()) / (x.std()))\n",
        "# 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0\n",
        "all_features[numeric_features] = all_features[numeric_features].fillna(0)"
      ],
      "metadata": {
        "id": "75emFf3yEpKP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# “Dummy_na=True”将“na”（缺失值）视为有效的特征值，并为其创建指示符特征\n",
        "all_features = pd.get_dummies(all_features, dummy_na=True)\n",
        "all_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5op4nh7ErSa",
        "outputId": "959d8c5b-01f3-4f1f-c07e-e2ef64597c4b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2919, 331)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_train = train_data.shape[0]\n",
        "train_features = torch.tensor(all_features[:n_train].values, dtype=torch.float32)\n",
        "test_features = torch.tensor(all_features[n_train:].values, dtype=torch.float32)\n",
        "train_labels = torch.tensor(\n",
        "    train_data.SalePrice.values.reshape(-1, 1), dtype=torch.float32)"
      ],
      "metadata": {
        "id": "2XKJ4_1lEs1F"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.MSELoss()\n",
        "in_features = train_features.shape[1]\n",
        "\n",
        "def get_net():\n",
        "    net = nn.Sequential(nn.Linear(in_features,1))\n",
        "    return net"
      ],
      "metadata": {
        "id": "U5cMr5KyEvQP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_rmse(net, features, labels):\n",
        "    # 为了在取对数时进一步稳定该值，将小于1的值设置为1\n",
        "    clipped_preds = torch.clamp(net(features), 1, float('inf'))\n",
        "    rmse = torch.sqrt(loss(torch.log(clipped_preds),\n",
        "                           torch.log(labels)))\n",
        "    return rmse.item()"
      ],
      "metadata": {
        "id": "8U7XJ373Ey3l"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, train_features, train_labels, test_features, test_labels,\n",
        "          num_epochs, learning_rate, weight_decay, batch_size):\n",
        "    train_ls, test_ls = [], []\n",
        "    train_iter = d2l.load_array((train_features, train_labels), batch_size)\n",
        "    # 这里使用的是Adam优化算法\n",
        "    optimizer = torch.optim.Adam(net.parameters(),\n",
        "                                 lr = learning_rate,\n",
        "                                 weight_decay = weight_decay)\n",
        "    for epoch in range(num_epochs):\n",
        "        for X, y in train_iter:\n",
        "            optimizer.zero_grad()\n",
        "            l = loss(net(X), y)\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "        train_ls.append(log_rmse(net, train_features, train_labels))\n",
        "        if test_labels is not None:\n",
        "            test_ls.append(log_rmse(net, test_features, test_labels))\n",
        "    return train_ls, test_ls"
      ],
      "metadata": {
        "id": "SSF4giroE0PV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_k_fold_data(k, i, X, y):\n",
        "    assert k > 1\n",
        "    fold_size = X.shape[0] // k\n",
        "    X_train, y_train = None, None\n",
        "    for j in range(k):\n",
        "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
        "        X_part, y_part = X[idx, :], y[idx]\n",
        "        if j == i:\n",
        "            X_valid, y_valid = X_part, y_part\n",
        "        elif X_train is None:\n",
        "            X_train, y_train = X_part, y_part\n",
        "        else:\n",
        "            X_train = torch.cat([X_train, X_part], 0)\n",
        "            y_train = torch.cat([y_train, y_part], 0)\n",
        "    return X_train, y_train, X_valid, y_valid"
      ],
      "metadata": {
        "id": "QLJTJWIcE1cG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay,\n",
        "           batch_size):\n",
        "    train_l_sum, valid_l_sum = 0, 0\n",
        "    for i in range(k):\n",
        "        data = get_k_fold_data(k, i, X_train, y_train)\n",
        "        net = get_net()\n",
        "        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,\n",
        "                                   weight_decay, batch_size)\n",
        "        train_l_sum += train_ls[-1]\n",
        "        valid_l_sum += valid_ls[-1]\n",
        "        # if i == 0:\n",
        "        #     d2l.plot(list(range(1, num_epochs + 1)), [train_ls, valid_ls],\n",
        "        #              xlabel='epoch', ylabel='rmse', xlim=[1, num_epochs],\n",
        "        #              legend=['train', 'valid'], yscale='log')\n",
        "        print(f'折{i + 1}，训练log rmse{float(train_ls[-1]):f}, '\n",
        "              f'验证log rmse{float(valid_ls[-1]):f}')\n",
        "    return train_l_sum / k, valid_l_sum / k"
      ],
      "metadata": {
        "id": "wtl43xwwE7x2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k, num_epochs, lr, weight_decay, batch_size = 5, 100, 5, 0, 64\n",
        "train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr,\n",
        "                          weight_decay, batch_size)\n",
        "print(f'{k}-折验证: 平均训练log rmse: {float(train_l):f}, '\n",
        "      f'平均验证log rmse: {float(valid_l):f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "snOCfPbTE2nk",
        "outputId": "afe9c059-e401-4e2c-9eed-224f677c710a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-eacdfa00e1c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr,\n\u001b[0;32m----> 3\u001b[0;31m                           weight_decay, batch_size)\n\u001b[0m\u001b[1;32m      4\u001b[0m print(f'{k}-折验证: 平均训练log rmse: {float(train_l):f}, '\n\u001b[1;32m      5\u001b[0m       f'平均验证log rmse: {float(valid_l):f}')\n",
            "\u001b[0;32m<ipython-input-21-694791026e4a>\u001b[0m in \u001b[0;36mk_fold\u001b[0;34m(k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,\n\u001b[0;32m----> 8\u001b[0;31m                                    weight_decay, batch_size)\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mtrain_l_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_ls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mvalid_l_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvalid_ls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-ab0d9200783b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_features, train_labels, test_features, test_labels, num_epochs, learning_rate, weight_decay, batch_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m           num_epochs, learning_rate, weight_decay, batch_size):\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_ls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# 这里使用的是Adam优化算法\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     optimizer = torch.optim.Adam(net.parameters(),\n",
            "\u001b[0;31mNameError\u001b[0m: name 'd2l' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Fz8sDk5wE4lO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}