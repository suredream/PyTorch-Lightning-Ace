{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOOfWukFnSrA4dxBUXRVHap",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suredream/PyTorch-Lightning-Ace/blob/main/pll-ray-tune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Mi4RfbwrPPj"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# install dependency & watermask\n",
        "!pip install -q pytorch-lightning lightning-bolts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep \"pytorch-lightning\\|lightning-bolts\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxVcd-SyrT4o",
        "outputId": "8c65346a-833f-408b-eab1-0affcefb80ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lightning-bolts               0.5.0\n",
            "pytorch-lightning             1.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "https://jovian.ai/venkatesh-vran/06-stl10-project\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "TI59JhJQtCXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pl_bolts.datamodules import STL10DataModule\n",
        "from pytorch_lightning import LightningModule, Trainer\n",
        "import torchvision.models as models\n",
        "from pl_bolts.callbacks import ORTCallback\n",
        "\n",
        "# dm\n",
        "dm = STL10DataModule('.')\n",
        "\n",
        "# model\n",
        "model = VisionModel()\n",
        "# trainer = Trainer(gpus=1, callbacks=ORTCallback())\n",
        "trainer.fit(model, datamodule=dm)"
      ],
      "metadata": {
        "id": "4WB1_hh_riFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python mnist_pytorch_lightning.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X51qKDfsVO6",
        "outputId": "1e56e03b-063b-499a-8f60-7b6731cda302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-25 21:40:50,011\tWARNING function_runner.py:604 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
            "2022-06-25 21:40:50,246\tWARNING tune.py:669 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:40:50 (running for 00:00:00.25)\n",
            "Memory usage on this node: 1.5/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 1.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+------------------------------+----------+----------------+----------------+----------------+-------------+--------------+\n",
            "| Trial name                   | status   | loc            |   layer_1_size |   layer_2_size |          lr |   batch_size |\n",
            "|------------------------------+----------+----------------+----------------+----------------+-------------+--------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988 |             32 |             64 | 0.00121565  |          128 |\n",
            "| train_mnist_tune_7afd1_00001 | PENDING  |                |            128 |            256 | 0.000991489 |           64 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                |             64 |             64 | 0.000699481 |           64 |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                |            128 |            128 | 0.000210866 |           32 |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                |             64 |            128 | 0.00107288  |          128 |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                |             32 |            128 | 0.000679803 |           32 |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                |             64 |            256 | 0.00873455  |           32 |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                |             32 |            128 | 0.00263816  |           64 |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                |             64 |            128 | 0.0147875   |          128 |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                |            128 |            128 | 0.000344075 |           32 |\n",
            "+------------------------------+----------+----------------+----------------+----------------+-------------+--------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m GPU available: False, used: False\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:336: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m   \"The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7.\"\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:348: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m   \"The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\"\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:377: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m   f\"The `Callback.{hook}` hook was deprecated in v1.6 and\"\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:377: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m   f\"The `Callback.{hook}` hook was deprecated in v1.6 and\"\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:386: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m   f\"The `Callback.{hook}` hook was deprecated in v1.6 and\"\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:386: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m   f\"The `Callback.{hook}` hook was deprecated in v1.6 and\"\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/data/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "  0%|          | 0/9912422 [00:00<?, ?it/s]\n",
            " 36%|███▌      | 3548160/9912422 [00:00<00:00, 35479434.51it/s]\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m Extracting /root/data/MNIST/raw/train-images-idx3-ubyte.gz to /root/data/MNIST/raw\n",
            "9913344it [00:00, 59786988.21it/s]                             \n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m Extracting /root/data/MNIST/raw/train-labels-idx1-ubyte.gz to /root/data/MNIST/raw\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "29696it [00:00, 63775756.06it/s]         \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m Extracting /root/data/MNIST/raw/t10k-images-idx3-ubyte.gz to /root/data/MNIST/raw\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "1649664it [00:00, 20986582.53it/s]         \n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m Extracting /root/data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /root/data/MNIST/raw\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m \n",
            "5120it [00:00, 24514653.52it/s]         \n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m   | Name    | Type   | Params\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m -----------------------------------\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m 0 | layer_1 | Linear | 25.1 K\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m 1 | layer_2 | Linear | 2.1 K \n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m 2 | layer_3 | Linear | 650   \n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m -----------------------------------\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m 27.9 K    Trainable params\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m 0         Non-trainable params\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m 27.9 K    Total params\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=988)\u001b[0m 0.112     Total estimated model params size (MB)\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m GPU available: False, used: False\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:336: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m   \"The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7.\"\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:348: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m   \"The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\"\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:377: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m   f\"The `Callback.{hook}` hook was deprecated in v1.6 and\"\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:377: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m   f\"The `Callback.{hook}` hook was deprecated in v1.6 and\"\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:386: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m   f\"The `Callback.{hook}` hook was deprecated in v1.6 and\"\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:386: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m   f\"The `Callback.{hook}` hook was deprecated in v1.6 and\"\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m   | Name    | Type   | Params\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m -----------------------------------\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m 0 | layer_1 | Linear | 100 K \n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m 1 | layer_2 | Linear | 33.0 K\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m 2 | layer_3 | Linear | 2.6 K \n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m -----------------------------------\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m 136 K     Trainable params\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m 0         Non-trainable params\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m 136 K     Total params\n",
            "\u001b[2m\u001b[36m(train_mnist_tune pid=1022)\u001b[0m 0.544     Total estimated model params size (MB)\n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:40:57 (running for 00:00:07.69)\n",
            "Memory usage on this node: 2.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:41:02 (running for 00:00:12.70)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:41:07 (running for 00:00:17.71)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:41:12 (running for 00:00:22.71)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+\n",
            "\n",
            "\n",
            "Result for train_mnist_tune_7afd1_00000:\n",
            "  date: 2022-06-25_21-41-17\n",
            "  done: false\n",
            "  experiment_id: e8a67bf30b504fe39e6a2ae408675c3d\n",
            "  hostname: 2692434dce7f\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.2499326914548874\n",
            "  mean_accuracy: 0.927734375\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 988\n",
            "  time_since_restore: 24.4146625995636\n",
            "  time_this_iter_s: 24.4146625995636\n",
            "  time_total_s: 24.4146625995636\n",
            "  timestamp: 1656193277\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 7afd1_00000\n",
            "  warmup_time: 0.003993034362792969\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:41:22 (running for 00:00:32.10)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -0.2499326914548874\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Current best trial: 7afd1_00000 with loss=0.2499326914548874 and parameters={'layer_1_size': 32, 'layer_2_size': 64, 'lr': 0.0012156521902859756, 'batch_size': 128}\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |     loss |   mean_accuracy |   training_iteration |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 | 0.249933 |        0.927734 |                    1 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |          |                 |                      |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_mnist_tune_7afd1_00001:\n",
            "  date: 2022-06-25_21-41-23\n",
            "  done: false\n",
            "  experiment_id: c5fc3e071d714b5e91b6009ef3679cfa\n",
            "  hostname: 2692434dce7f\n",
            "  iterations_since_restore: 1\n",
            "  loss: 0.14060132205486298\n",
            "  mean_accuracy: 0.9564873576164246\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1022\n",
            "  time_since_restore: 27.11305260658264\n",
            "  time_this_iter_s: 27.11305260658264\n",
            "  time_total_s: 27.11305260658264\n",
            "  timestamp: 1656193283\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 1\n",
            "  trial_id: 7afd1_00001\n",
            "  warmup_time: 0.0042476654052734375\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:41:28 (running for 00:00:38.60)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -0.19526700675487518\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Current best trial: 7afd1_00001 with loss=0.14060132205486298 and parameters={'layer_1_size': 128, 'layer_2_size': 256, 'lr': 0.0009914887060526192, 'batch_size': 64}\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |     loss |   mean_accuracy |   training_iteration |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 | 0.249933 |        0.927734 |                    1 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 | 0.140601 |        0.956487 |                    1 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |          |                 |                      |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:41:33 (running for 00:00:43.61)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -0.19526700675487518\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Current best trial: 7afd1_00001 with loss=0.14060132205486298 and parameters={'layer_1_size': 128, 'layer_2_size': 256, 'lr': 0.0009914887060526192, 'batch_size': 64}\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |     loss |   mean_accuracy |   training_iteration |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 | 0.249933 |        0.927734 |                    1 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 | 0.140601 |        0.956487 |                    1 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |          |                 |                      |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_mnist_tune_7afd1_00000:\n",
            "  date: 2022-06-25_21-41-36\n",
            "  done: false\n",
            "  experiment_id: e8a67bf30b504fe39e6a2ae408675c3d\n",
            "  hostname: 2692434dce7f\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.19300393760204315\n",
            "  mean_accuracy: 0.940625011920929\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 988\n",
            "  time_since_restore: 43.78408169746399\n",
            "  time_this_iter_s: 19.36941909790039\n",
            "  time_total_s: 43.78408169746399\n",
            "  timestamp: 1656193296\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 2\n",
            "  trial_id: 7afd1_00000\n",
            "  warmup_time: 0.003993034362792969\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:41:41 (running for 00:00:51.47)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -0.19300393760204315 | Iter 1.000: -0.19526700675487518\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Current best trial: 7afd1_00001 with loss=0.14060132205486298 and parameters={'layer_1_size': 128, 'layer_2_size': 256, 'lr': 0.0009914887060526192, 'batch_size': 64}\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |     loss |   mean_accuracy |   training_iteration |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 | 0.193004 |        0.940625 |                    2 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 | 0.140601 |        0.956487 |                    1 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |          |                 |                      |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:41:46 (running for 00:00:56.49)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -0.19300393760204315 | Iter 1.000: -0.19526700675487518\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Current best trial: 7afd1_00001 with loss=0.14060132205486298 and parameters={'layer_1_size': 128, 'layer_2_size': 256, 'lr': 0.0009914887060526192, 'batch_size': 64}\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |     loss |   mean_accuracy |   training_iteration |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 | 0.193004 |        0.940625 |                    2 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 | 0.140601 |        0.956487 |                    1 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |          |                 |                      |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_mnist_tune_7afd1_00001:\n",
            "  date: 2022-06-25_21-41-46\n",
            "  done: false\n",
            "  experiment_id: c5fc3e071d714b5e91b6009ef3679cfa\n",
            "  hostname: 2692434dce7f\n",
            "  iterations_since_restore: 2\n",
            "  loss: 0.10999376326799393\n",
            "  mean_accuracy: 0.9657832384109497\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1022\n",
            "  time_since_restore: 50.03544735908508\n",
            "  time_this_iter_s: 22.92239475250244\n",
            "  time_total_s: 50.03544735908508\n",
            "  timestamp: 1656193306\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 2\n",
            "  trial_id: 7afd1_00001\n",
            "  warmup_time: 0.0042476654052734375\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:41:51 (running for 00:01:01.51)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -0.15149885043501854 | Iter 1.000: -0.19526700675487518\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Current best trial: 7afd1_00001 with loss=0.10999376326799393 and parameters={'layer_1_size': 128, 'layer_2_size': 256, 'lr': 0.0009914887060526192, 'batch_size': 64}\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |     loss |   mean_accuracy |   training_iteration |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 | 0.193004 |        0.940625 |                    2 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 | 0.109994 |        0.965783 |                    2 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |          |                 |                      |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_mnist_tune_7afd1_00000:\n",
            "  date: 2022-06-25_21-41-56\n",
            "  done: false\n",
            "  experiment_id: e8a67bf30b504fe39e6a2ae408675c3d\n",
            "  hostname: 2692434dce7f\n",
            "  iterations_since_restore: 3\n",
            "  loss: 0.1710088700056076\n",
            "  mean_accuracy: 0.9478515386581421\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 988\n",
            "  time_since_restore: 63.288795471191406\n",
            "  time_this_iter_s: 19.504713773727417\n",
            "  time_total_s: 63.288795471191406\n",
            "  timestamp: 1656193316\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 3\n",
            "  trial_id: 7afd1_00000\n",
            "  warmup_time: 0.003993034362792969\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:42:01 (running for 00:01:10.98)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -0.15149885043501854 | Iter 1.000: -0.19526700675487518\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Current best trial: 7afd1_00001 with loss=0.10999376326799393 and parameters={'layer_1_size': 128, 'layer_2_size': 256, 'lr': 0.0009914887060526192, 'batch_size': 64}\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |     loss |   mean_accuracy |   training_iteration |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 | 0.171009 |        0.947852 |                    3 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 | 0.109994 |        0.965783 |                    2 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |          |                 |                      |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:42:06 (running for 00:01:16.01)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -0.15149885043501854 | Iter 1.000: -0.19526700675487518\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Current best trial: 7afd1_00001 with loss=0.10999376326799393 and parameters={'layer_1_size': 128, 'layer_2_size': 256, 'lr': 0.0009914887060526192, 'batch_size': 64}\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |     loss |   mean_accuracy |   training_iteration |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 | 0.171009 |        0.947852 |                    3 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 | 0.109994 |        0.965783 |                    2 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |          |                 |                      |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_mnist_tune_7afd1_00001:\n",
            "  date: 2022-06-25_21-42-10\n",
            "  done: false\n",
            "  experiment_id: c5fc3e071d714b5e91b6009ef3679cfa\n",
            "  hostname: 2692434dce7f\n",
            "  iterations_since_restore: 3\n",
            "  loss: 0.12045887857675552\n",
            "  mean_accuracy: 0.9647942781448364\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1022\n",
            "  time_since_restore: 73.95124292373657\n",
            "  time_this_iter_s: 23.91579556465149\n",
            "  time_total_s: 73.95124292373657\n",
            "  timestamp: 1656193330\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 3\n",
            "  trial_id: 7afd1_00001\n",
            "  warmup_time: 0.0042476654052734375\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:42:15 (running for 00:01:25.43)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -0.15149885043501854 | Iter 1.000: -0.19526700675487518\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Current best trial: 7afd1_00001 with loss=0.12045887857675552 and parameters={'layer_1_size': 128, 'layer_2_size': 256, 'lr': 0.0009914887060526192, 'batch_size': 64}\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |     loss |   mean_accuracy |   training_iteration |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 | 0.171009 |        0.947852 |                    3 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 | 0.120459 |        0.964794 |                    3 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |          |                 |                      |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_mnist_tune_7afd1_00000:\n",
            "  date: 2022-06-25_21-42-16\n",
            "  done: false\n",
            "  experiment_id: e8a67bf30b504fe39e6a2ae408675c3d\n",
            "  hostname: 2692434dce7f\n",
            "  iterations_since_restore: 4\n",
            "  loss: 0.15578189492225647\n",
            "  mean_accuracy: 0.950976550579071\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 988\n",
            "  time_since_restore: 83.28272366523743\n",
            "  time_this_iter_s: 19.99392819404602\n",
            "  time_total_s: 83.28272366523743\n",
            "  timestamp: 1656193336\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 4\n",
            "  trial_id: 7afd1_00000\n",
            "  warmup_time: 0.003993034362792969\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:42:21 (running for 00:01:30.96)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: -0.15578189492225647 | Iter 2.000: -0.15149885043501854 | Iter 1.000: -0.19526700675487518\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Current best trial: 7afd1_00001 with loss=0.12045887857675552 and parameters={'layer_1_size': 128, 'layer_2_size': 256, 'lr': 0.0009914887060526192, 'batch_size': 64}\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |     loss |   mean_accuracy |   training_iteration |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 | 0.155782 |        0.950977 |                    4 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 | 0.120459 |        0.964794 |                    3 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |          |                 |                      |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:42:26 (running for 00:01:35.98)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: -0.15578189492225647 | Iter 2.000: -0.15149885043501854 | Iter 1.000: -0.19526700675487518\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Current best trial: 7afd1_00001 with loss=0.12045887857675552 and parameters={'layer_1_size': 128, 'layer_2_size': 256, 'lr': 0.0009914887060526192, 'batch_size': 64}\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |     loss |   mean_accuracy |   training_iteration |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 | 0.155782 |        0.950977 |                    4 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 | 0.120459 |        0.964794 |                    3 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |          |                 |                      |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:42:31 (running for 00:01:40.99)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: -0.15578189492225647 | Iter 2.000: -0.15149885043501854 | Iter 1.000: -0.19526700675487518\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Current best trial: 7afd1_00001 with loss=0.12045887857675552 and parameters={'layer_1_size': 128, 'layer_2_size': 256, 'lr': 0.0009914887060526192, 'batch_size': 64}\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |     loss |   mean_accuracy |   training_iteration |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 | 0.155782 |        0.950977 |                    4 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 | 0.120459 |        0.964794 |                    3 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |          |                 |                      |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_mnist_tune_7afd1_00001:\n",
            "  date: 2022-06-25_21-42-34\n",
            "  done: false\n",
            "  experiment_id: c5fc3e071d714b5e91b6009ef3679cfa\n",
            "  hostname: 2692434dce7f\n",
            "  iterations_since_restore: 4\n",
            "  loss: 0.08369903266429901\n",
            "  mean_accuracy: 0.9756724834442139\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1022\n",
            "  time_since_restore: 97.4727714061737\n",
            "  time_this_iter_s: 23.521528482437134\n",
            "  time_total_s: 97.4727714061737\n",
            "  timestamp: 1656193354\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 4\n",
            "  trial_id: 7afd1_00001\n",
            "  warmup_time: 0.0042476654052734375\n",
            "  \n",
            "Result for train_mnist_tune_7afd1_00000:\n",
            "  date: 2022-06-25_21-42-35\n",
            "  done: false\n",
            "  experiment_id: e8a67bf30b504fe39e6a2ae408675c3d\n",
            "  hostname: 2692434dce7f\n",
            "  iterations_since_restore: 5\n",
            "  loss: 0.1482812464237213\n",
            "  mean_accuracy: 0.955859363079071\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 988\n",
            "  time_since_restore: 102.74955821037292\n",
            "  time_this_iter_s: 19.466834545135498\n",
            "  time_total_s: 102.74955821037292\n",
            "  timestamp: 1656193355\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 5\n",
            "  trial_id: 7afd1_00000\n",
            "  warmup_time: 0.003993034362792969\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:42:40 (running for 00:01:50.44)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: -0.11974046379327774 | Iter 2.000: -0.15149885043501854 | Iter 1.000: -0.19526700675487518\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Current best trial: 7afd1_00001 with loss=0.08369903266429901 and parameters={'layer_1_size': 128, 'layer_2_size': 256, 'lr': 0.0009914887060526192, 'batch_size': 64}\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |     loss |   mean_accuracy |   training_iteration |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 | 0.148281 |        0.955859 |                    5 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 | 0.083699 |        0.975672 |                    4 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |          |                 |                      |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:42:45 (running for 00:01:55.46)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: -0.11974046379327774 | Iter 2.000: -0.15149885043501854 | Iter 1.000: -0.19526700675487518\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Current best trial: 7afd1_00001 with loss=0.08369903266429901 and parameters={'layer_1_size': 128, 'layer_2_size': 256, 'lr': 0.0009914887060526192, 'batch_size': 64}\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |     loss |   mean_accuracy |   training_iteration |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 | 0.148281 |        0.955859 |                    5 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 | 0.083699 |        0.975672 |                    4 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |          |                 |                      |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:42:50 (running for 00:02:00.47)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: -0.11974046379327774 | Iter 2.000: -0.15149885043501854 | Iter 1.000: -0.19526700675487518\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Current best trial: 7afd1_00001 with loss=0.08369903266429901 and parameters={'layer_1_size': 128, 'layer_2_size': 256, 'lr': 0.0009914887060526192, 'batch_size': 64}\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |     loss |   mean_accuracy |   training_iteration |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 | 0.148281 |        0.955859 |                    5 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 | 0.083699 |        0.975672 |                    4 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |          |                 |                      |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |          |                 |                      |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+----------+-----------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_mnist_tune_7afd1_00000:\n",
            "  date: 2022-06-25_21-42-54\n",
            "  done: false\n",
            "  experiment_id: e8a67bf30b504fe39e6a2ae408675c3d\n",
            "  hostname: 2692434dce7f\n",
            "  iterations_since_restore: 6\n",
            "  loss: 0.14715896546840668\n",
            "  mean_accuracy: 0.9574218988418579\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 988\n",
            "  time_since_restore: 121.96447086334229\n",
            "  time_this_iter_s: 19.21491265296936\n",
            "  time_total_s: 121.96447086334229\n",
            "  timestamp: 1656193374\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 6\n",
            "  trial_id: 7afd1_00000\n",
            "  warmup_time: 0.003993034362792969\n",
            "  \n",
            "Result for train_mnist_tune_7afd1_00001:\n",
            "  date: 2022-06-25_21-42-56\n",
            "  done: false\n",
            "  experiment_id: c5fc3e071d714b5e91b6009ef3679cfa\n",
            "  hostname: 2692434dce7f\n",
            "  iterations_since_restore: 5\n",
            "  loss: 0.08788469433784485\n",
            "  mean_accuracy: 0.9764636158943176\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1022\n",
            "  time_since_restore: 120.20133447647095\n",
            "  time_this_iter_s: 22.72856307029724\n",
            "  time_total_s: 120.20133447647095\n",
            "  timestamp: 1656193376\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 5\n",
            "  trial_id: 7afd1_00001\n",
            "  warmup_time: 0.0042476654052734375\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:42:56 (running for 00:02:06.66)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: -0.11974046379327774 | Iter 2.000: -0.15149885043501854 | Iter 1.000: -0.19526700675487518\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Current best trial: 7afd1_00001 with loss=0.08788469433784485 and parameters={'layer_1_size': 128, 'layer_2_size': 256, 'lr': 0.0009914887060526192, 'batch_size': 64}\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+-----------+-----------------+----------------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |      loss |   mean_accuracy |   training_iteration |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+-----------+-----------------+----------------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 | 0.147159  |        0.957422 |                    6 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 | 0.0878847 |        0.976464 |                    5 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |           |                 |                      |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+-----------+-----------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:43:01 (running for 00:02:11.69)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: -0.11974046379327774 | Iter 2.000: -0.15149885043501854 | Iter 1.000: -0.19526700675487518\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Current best trial: 7afd1_00001 with loss=0.08788469433784485 and parameters={'layer_1_size': 128, 'layer_2_size': 256, 'lr': 0.0009914887060526192, 'batch_size': 64}\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+-----------+-----------------+----------------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |      loss |   mean_accuracy |   training_iteration |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+-----------+-----------------+----------------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 | 0.147159  |        0.957422 |                    6 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 | 0.0878847 |        0.976464 |                    5 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |           |                 |                      |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+-----------+-----------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:43:06 (running for 00:02:16.70)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: -0.11974046379327774 | Iter 2.000: -0.15149885043501854 | Iter 1.000: -0.19526700675487518\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Current best trial: 7afd1_00001 with loss=0.08788469433784485 and parameters={'layer_1_size': 128, 'layer_2_size': 256, 'lr': 0.0009914887060526192, 'batch_size': 64}\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+-----------+-----------------+----------------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |      loss |   mean_accuracy |   training_iteration |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+-----------+-----------------+----------------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 | 0.147159  |        0.957422 |                    6 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 | 0.0878847 |        0.976464 |                    5 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |           |                 |                      |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+-----------+-----------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-06-25 21:43:11 (running for 00:02:21.71)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: -0.11974046379327774 | Iter 2.000: -0.15149885043501854 | Iter 1.000: -0.19526700675487518\n",
            "Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P100)\n",
            "Current best trial: 7afd1_00001 with loss=0.08788469433784485 and parameters={'layer_1_size': 128, 'layer_2_size': 256, 'lr': 0.0009914887060526192, 'batch_size': 64}\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+-----------+-----------------+----------------------+\n",
            "| Trial name                   | status   | loc             |   layer_1_size |   layer_2_size |          lr |   batch_size |      loss |   mean_accuracy |   training_iteration |\n",
            "|------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+-----------+-----------------+----------------------|\n",
            "| train_mnist_tune_7afd1_00000 | RUNNING  | 172.28.0.2:988  |             32 |             64 | 0.00121565  |          128 | 0.147159  |        0.957422 |                    6 |\n",
            "| train_mnist_tune_7afd1_00001 | RUNNING  | 172.28.0.2:1022 |            128 |            256 | 0.000991489 |           64 | 0.0878847 |        0.976464 |                    5 |\n",
            "| train_mnist_tune_7afd1_00002 | PENDING  |                 |             64 |             64 | 0.000699481 |           64 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00003 | PENDING  |                 |            128 |            128 | 0.000210866 |           32 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00004 | PENDING  |                 |             64 |            128 | 0.00107288  |          128 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00005 | PENDING  |                 |             32 |            128 | 0.000679803 |           32 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00006 | PENDING  |                 |             64 |            256 | 0.00873455  |           32 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00007 | PENDING  |                 |             32 |            128 | 0.00263816  |           64 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00008 | PENDING  |                 |             64 |            128 | 0.0147875   |          128 |           |                 |                      |\n",
            "| train_mnist_tune_7afd1_00009 | PENDING  |                 |            128 |            128 | 0.000344075 |           32 |           |                 |                      |\n",
            "+------------------------------+----------+-----------------+----------------+----------------+-------------+--------------+-----------+-----------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_mnist_tune_7afd1_00000:\n",
            "  date: 2022-06-25_21-43-13\n",
            "  done: false\n",
            "  experiment_id: e8a67bf30b504fe39e6a2ae408675c3d\n",
            "  hostname: 2692434dce7f\n",
            "  iterations_since_restore: 7\n",
            "  loss: 0.1441289335489273\n",
            "  mean_accuracy: 0.9583984613418579\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 988\n",
            "  time_since_restore: 140.8596510887146\n",
            "  time_this_iter_s: 18.895180225372314\n",
            "  time_total_s: 140.8596510887146\n",
            "  timestamp: 1656193393\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 7\n",
            "  trial_id: 7afd1_00000\n",
            "  warmup_time: 0.003993034362792969\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## If you are running on Google Colab, uncomment below to install the necessary dependencies \n",
        "## before beginning the exercise.\n",
        "\n",
        "# print(\"Setting up colab environment\")\n",
        "!pip uninstall -y -q pyarrow\n",
        "!pip install -q -U ray[tune]\n",
        "!pip install -q ray\n",
        "\n",
        "# # A hack to force the runtime to restart, needed to include the above dependencies.\n",
        "print(\"Done installing! Restarting via forced crash (this is not an issue).\")\n",
        "import os\n",
        "os._exit(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCyWPs1Av8QH",
        "outputId": "3e71170f-7b7d-4b9f-9566-941d456f2a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping pyarrow as it is not installed.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0QyIupErwA7a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}